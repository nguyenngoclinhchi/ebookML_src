{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy and pandas working together\n",
    "Pandas depends upon and interoperates with NumPy, the Python library for fast numeric array computations. For example, you can use the DataFrame attribute .values to represent a DataFrame `df` as a NumPy array. You can also pass pandas data structures to NumPy methods. In this exercise, we have imported pandas as pd and loaded world population data every 10 years since 1960 into the DataFrame df. This dataset was derived from the one used in the previous exercise.\n",
    "\n",
    "Your job is to extract the values and store them in an array using the attribute .values. You'll then use those values as input into the NumPy `np.log10()` method to compute the base 10 logarithm of the population values. Finally, you will pass the entire pandas DataFrame into the same NumPy `np.log10()` method and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create array of DataFrame values: np_vals\n",
    "np_vals = df.values\n",
    "\n",
    "# Create new array of base 10 logarithm values: np_vals_log10\n",
    "np_vals_log10 = np.log10(np_vals)\n",
    "\n",
    "# Create array of new DataFrame by passing df to np.log10(): df_log10\n",
    "df_log10 = np.log10(df)\n",
    "\n",
    "# Print original and new data containers\n",
    "[print(x, 'has type', type(eval(x))) for x in ['np_vals', 'np_vals_log10', 'df', 'df_log10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip lists to build a DataFrame\n",
    "In this exercise, you're going to make a pandas DataFrame of the top three countries to win gold medals since 1896 by first building a dictionary. list_keys contains the column names 'Country' and 'Total'. list_values contains the full names of each country and the number of gold medals awarded. The values have been taken from Wikipedia.\n",
    "\n",
    "Your job is to use these lists to construct a list of tuples, use the list of tuples to construct a dictionary, and then use that dictionary to construct a DataFrame. In doing so, you'll make use of the `list(), zip(), dict() and pd.DataFrame()` functions. Pandas has already been imported as pd.\n",
    "\n",
    "Note: The `zip()` function in Python 3 and above returns a special zip object, which is essentially a generator. To convert this zip object into a list, you'll need to use `list()`. You can learn more about the `zip()` function as well as generators in Python Data Science Toolbox (Part 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the 2 lists together into one list of (key,value) tuples: zipped\n",
    "zipped = list(zip(list_keys, list_values))\n",
    "\n",
    "# Inspect the list using print()\n",
    "print(zipped)\n",
    "\n",
    "# # Build a dictionary with the zipped list: data\n",
    "data = dict(zipped)\n",
    "\n",
    "# # Build and inspect a DataFrame from the dictionary: df\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling your data\n",
    "You can use the DataFrame attribute df.columns to view and assign new string labels to columns in a pandas DataFrame.\n",
    "\n",
    "In this exercise, we have imported pandas as pd and defined a DataFrame df containing top Billboard hits from the 1980s (from Wikipedia). Each row has the year, artist, song name and the number of weeks at the top. However, this DataFrame has the column labels a, b, c, d. Your job is to use the `df.columns` attribute to re-assign descriptive column labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of labels: list_labels\n",
    "list_labels = list(['year', 'artist', 'song', 'chart weeks'])\n",
    "\n",
    "# Assign the list of labels to the columns attribute: df.columns\n",
    "df.columns = list_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building DataFrames with broadcasting\n",
    "You can implicitly use 'broadcasting', a feature of NumPy, when creating pandas DataFrames. In this exercise, you're going to create a DataFrame of cities in Pennsylvania that contains the city name in one column and the state name in the second. We have imported the names of 15 cities as the list `cities`.\n",
    "\n",
    "Your job is to construct a DataFrame from the list of cities and the string `'PA'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a string with the value 'PA': state\n",
    "state = 'PA'\n",
    "\n",
    "# Construct a dictionary: data\n",
    "data = {'state':state, 'city':cities}\n",
    "\n",
    "# Construct a DataFrame from dictionary data: df\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading a flat file\n",
    "In previous exercises, we have preloaded the data for you using the pandas function `read_csv()`. Now, it's your turn! Your job is to read the World Bank population data you saw earlier into a DataFrame using `read_csv()`. The file is available in the variable data_file.\n",
    "\n",
    "The next step is to reread the same file, but simultaneously rename the columns using the names keyword input parameter, set equal to a list of new column labels. You will also need to set `header=0` to rename the column labels.\n",
    "\n",
    "Finish up by inspecting the result with `df.head() and df.info()` in the IPython Shell (changing df to the name of your DataFrame variable).\n",
    "\n",
    "pandas has already been imported and is available in the workspace as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file: df1\n",
    "df1 = pd.read_csv(data_file)\n",
    "\n",
    "# Create a list of the new column labels: new_labels\n",
    "new_labels = ['year', 'population']\n",
    "\n",
    "# Read in the file, specifying the header and names parameters: df2\n",
    "df2 = pd.read_csv(data_file, header=0, names=new_labels)\n",
    "\n",
    "# Print both the DataFrames\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delimiters, headers, and extensions\n",
    "Not all data files are clean and tidy. Pandas provides methods for reading those not-so-perfect data files that you encounter far too often.\n",
    "\n",
    "In this exercise, you have monthly stock data for four companies downloaded from Yahoo Finance. The data is stored as one row for each company and each column is the end-of-month closing price. The file name is given to you in the variable `file_messy`.\n",
    "\n",
    "In addition, this file has three aspects that may cause trouble for lesser tools: multiple header lines, comment records (rows) interleaved throughout the data rows, and space delimiters instead of commas.\n",
    "\n",
    "Your job is to use pandas to read the data from this problematic file_messy using non-default input options with `read_csv()` so as to tidy up the mess at read time. Then, write the cleaned up data to a CSV file with the variable file_clean that has been prepared for you, as you might do in a real data workflow.\n",
    "\n",
    "You can learn about the option input parameters needed by using `help()` on the pandas function `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw file as-is: df1\n",
    "df1 = pd.read_csv(file_messy)\n",
    "\n",
    "# Print the output of df1.head()\n",
    "print(df1.head())\n",
    "\n",
    "# Read in the file with the correct parameters: df2\n",
    "df2 = pd.read_csv(file_messy, delimiter=' ', header=3, comment='#')\n",
    "\n",
    "# Print the output of df2.head()\n",
    "print(df2.head())\n",
    "\n",
    "# Save the cleaned up DataFrame to a CSV file without the index\n",
    "df2.to_csv(file_clean, index=False)\n",
    "\n",
    "# Save the cleaned up DataFrame to an excel file without the index\n",
    "df2.to_excel('file_clean.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting series using pandas\n",
    "Data visualization is often a very effective first step in gaining a rough understanding of a data set to be analyzed. Pandas provides data visualization by both depending upon and interoperating with the matplotlib library. You will now explore some of the basic plotting mechanics with pandas as well as related matplotlib options. We have pre-loaded a pandas DataFrame df which contains the data you need. Your job is to use the DataFrame method `df.plot()` to visualize the data, and then explore the optional matplotlib input parameters that this `.plot()` method accepts.\n",
    "\n",
    "The pandas `.plot()` method makes calls to matplotlib to construct the plots. This means that you can use the skills you've learned in previous visualization courses to customize the plot. In this exercise, you'll add a custom title and axis labels to the figure.\n",
    "\n",
    "Before plotting, inspect the DataFrame in the IPython Shell using `df.head()`. Also, use `type(df)` and note that it is a single column DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a plot with color='red'\n",
    "df.plot(color='red')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Temperature in Austin')\n",
    "\n",
    "# Specify the x-axis label\n",
    "plt.xlabel('Hours since midnight August 1, 2010')\n",
    "\n",
    "# Specify the y-axis label\n",
    "plt.ylabel('Temperature (degrees F)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting DataFrames\n",
    "Comparing data from several columns can be very illuminating. Pandas makes doing so easy with multi-column DataFrames. By default, calling `df.plot()` will cause pandas to over-plot all column data, with each column as a single line. In this exercise, we have pre-loaded three columns of data from a weather data set - temperature, dew point, and pressure - but the problem is that pressure has different units of measure. The pressure data, measured in Atmospheres, has a different vertical scaling than that of the other two data columns, which are both measured in degrees Fahrenheit.\n",
    "\n",
    "Your job is to plot all columns as a multi-line plot, to see the nature of vertical scaling problem. Then, use a list of column names passed into the DataFrame `df[column_list]` to limit plotting to just one column, and then just 2 columns of data. When you are finished, you will have created 4 plots. You can cycle through them by clicking on the 'Previous Plot' and 'Next Plot' buttons.\n",
    "\n",
    "As in the previous exercise, inspect the DataFrame df in the IPython Shell using the `.head()` and `.info()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all columns (default)\n",
    "df.plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot all columns as subplots\n",
    "df.plot(subplots=True)\n",
    "plt.show()\n",
    "\n",
    "# Plot just the Dew Point data\n",
    "column_list1 = ['Dew Point (deg F)']\n",
    "df[column_list1].plot()\n",
    "plt.show()\n",
    "\n",
    "# Plot the Dew Point and Temperature data, but not the Pressure data\n",
    "column_list2 = ['Temperature (deg F)','Dew Point (deg F)']\n",
    "df[column_list2].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas line plots\n",
    "In the previous chapter, you saw that the .plot() method will place the Index values on the x-axis by default. In this exercise, you'll practice making line plots with specific columns on the x and y axes.\n",
    "\n",
    "You will work with a dataset consisting of monthly stock prices in 2015 for AAPL, GOOG, and IBM. The stock prices were obtained from Yahoo Finance. Your job is to plot the 'Month' column on the x-axis and the AAPL and IBM prices on the y-axis using a list of column names.\n",
    "\n",
    "All necessary modules have been imported for you, and the DataFrame is available in the workspace as df. Explore it using methods such as `.head(), .info(), and .describe()` to see the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of y-axis column names: y_columns\n",
    "y_columns = ['AAPL', 'IBM']\n",
    "\n",
    "# Generate a line plot\n",
    "df.plot(x='Month', y=y_columns)\n",
    "\n",
    "# Add the title\n",
    "plt.xlabel('Monthly stock prices')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Price ($US)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas scatter plots\n",
    "Pandas scatter plots are generated using the `kind='scatter'` keyword argument. Scatter plots require that the x and y columns be chosen by specifying the x and y parameters inside `.plot()`. Scatter plots also take an s keyword argument to provide the radius of each circle to plot in pixels.\n",
    "\n",
    "In this exercise, you're going to plot fuel efficiency (miles-per-gallon) versus horse-power for 392 automobiles manufactured from 1970 to 1982 from the UCI Machine Learning Repository.\n",
    "\n",
    "The size of each circle is provided as a NumPy array called sizes. This array contains the normalized `'weight'` of each automobile in the dataset.\n",
    "\n",
    "All necessary modules have been imported and the DataFrame is available in the workspace as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a scatter plot\n",
    "df.plot(kind='scatter', x='hp', y='mpg', s=sizes)\n",
    "\n",
    "# Add the title\n",
    "plt.title('Fuel efficiency vs Horse-power')\n",
    "\n",
    "# Add the x-axis label\n",
    "plt.xlabel('Horse-power')\n",
    "\n",
    "# Add the y-axis label\n",
    "plt.ylabel('Fuel efficiency (mpg)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas box plots\n",
    "While pandas can plot multiple columns of data in a single figure, making plots that share the same x and y axes, there are cases where two columns cannot be plotted together because their units do not match. The .plot() method can generate subplots for each column being plotted. Here, each plot will be scaled independently.\n",
    "\n",
    "In this exercise your job is to generate box plots for fuel efficiency (mpg) and weight from the automobiles data set. To do this in a single figure, you'll specify subplots=True inside `.plot()` to generate two separate plots.\n",
    "\n",
    "All necessary modules have been imported and the automobiles dataset is available in the workspace as df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the column names to be plotted: cols\n",
    "cols = ['weight', 'mpg']\n",
    "\n",
    "# Generate the box plots\n",
    "df[cols].plot(subplots=True, kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas hist, pdf and cdf\n",
    "Pandas relies on the .hist() method to not only generate histograms, but also plots of `probability density functions (PDFs) and cumulative density functions (CDFs)`.\n",
    "\n",
    "In this exercise, you will work with a dataset consisting of restaurant bills that includes the amount customers tipped.\n",
    "\n",
    "The original dataset is provided by the Seaborn package.\n",
    "\n",
    "Your job is to plot a PDF and CDF for the fraction column of the tips dataset. This column contains information about what fraction of the total bill is comprised of the tip.\n",
    "\n",
    "Remember, when plotting the PDF, you need to specify normed=True in your call to `.hist()`, and when plotting the CDF, you need to specify `cumulative=True` in addition to normed=True.\n",
    "\n",
    "All necessary modules have been imported and the tips dataset is available in the workspace as df. Also, some formatting code has been written so that the plots you generate will appear on separate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This formats the plots such that they appear on separate rows\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Plot the PDF, if will appear on the first space, axes have 2 spaces\n",
    "df.fraction.plot(ax=axes[0], kind='hist', normed=True, bins=30, range=(0,.3))\n",
    "plt.show()\n",
    "\n",
    "# Plot the CDF, if will appear on the second space, axes have 2 spaces \n",
    "df.fraction.plot(ax=axes[1], kind='hist', normed=True, bins=30, range=(0,.3), cumulative=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box Plot\n",
    "The picture below shows the box plot structure:\n",
    "\n",
    "![Box Plot](BoxPlot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bachelor's degrees awarded to women\n",
    "In this exercise, you will investigate statistics of the percentage of Bachelor's degrees awarded to women from 1970 to 2011. Data is recorded every year for 17 different fields. This data set was obtained from the Digest of Education Statistics.\n",
    "\n",
    "Your job is to compute the minimum and maximum values of the `'Engineering'` column and generate a line plot of the mean value of all 17 academic fields per year. To perform this step, you'll use the `.mean()` method with the keyword argument `axis='columns'`. This computes the mean across all columns per row.\n",
    "\n",
    "The DataFrame has been pre-loaded for you as df with the index set to `'Year'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the minimum value of the Engineering column\n",
    "print(df['Engineering'].min())\n",
    "\n",
    "# Print the maximum value of the Engineering column\n",
    "print(df['Engineering'].max())\n",
    "\n",
    "# Construct the mean percentage per year: mean\n",
    "mean = df.mean(axis='columns')\n",
    "\n",
    "# Plot the average percentage per year\n",
    "mean.plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median vs mean\n",
    "In many data sets, there can be large differences in the mean and median value due to the presence of outliers.\n",
    "\n",
    "In this exercise, you'll investigate the mean, median, and max fare prices paid by passengers on the Titanic and generate a box plot of the fare prices. This data set was obtained from Vanderbilt University.\n",
    "\n",
    "All necessary modules have been imported and the DataFrame is available in the workspace as df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics of the fare column with .describe()\n",
    "print(df['fare'].describe())\n",
    "\n",
    "# Generate a box plot of the fare column\n",
    "df['fare'].plot(kind='box')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantiles\n",
    "In this exercise, you'll investigate the probabilities of life expectancy in countries around the world. This dataset contains life expectancy for persons born each year from 1800 to 2015. Since country names change or results are not reported, not every country has values. This dataset was obtained from Gapminder.\n",
    "\n",
    "First, you will determine the number of countries reported in 2015. There are a total of 260 unique countries in the entire dataset. Then, you will compute the 5th and 95th percentiles of life expectancy over the entire dataset. Finally, you will make a box plot of life expectancy every 50 years from 1800 to 2000. Notice the large change in the distributions over this period.\n",
    "\n",
    "The dataset has been pre-loaded into a DataFrame called df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of countries reported in 2015\n",
    "print(df['2015'].count())\n",
    "\n",
    "# Print the 5th and 95th percentiles\n",
    "q=[0.05, 0.95]\n",
    "print(df.quantile(q))\n",
    "\n",
    "# Generate a box plot\n",
    "years = ['1800','1850','1900','1950','2000']\n",
    "df[years].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard deviation of temperature\n",
    "Let's use the mean and standard deviation to explore differences in temperature distributions in Pittsburgh in 2013. The data has been obtained from Weather Underground.\n",
    "\n",
    "In this exercise, you're going to compare the distribution of daily temperatures in January and March. You'll compute the mean and standard deviation for these two months. You will notice that while the mean values are similar, the standard deviations are quite different, meaning that one month had a larger fluctuation in temperature than the other.\n",
    "\n",
    "The DataFrames have been pre-loaded for you as january, which contains the January data, and march, which contains the March data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean of the January and March data\n",
    "print(january.mean(), march.mean())\n",
    "\n",
    "# Print the standard deviation of the January and March data\n",
    "print(january.std(), march.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate and summarize\n",
    "Let's use population filtering to determine how the automobiles in the US differ from the global average and standard deviation. How does the distribution of fuel efficiency (MPG) for the US differ from the global average and standard deviation?\n",
    "\n",
    "In this exercise, you'll compute the means and standard deviations of all columns in the full automobile dataset. Next, you'll compute the same quantities for just the US population and subtract the global values from the US values.\n",
    "\n",
    "All necessary modules have been imported and the DataFrame has been pre-loaded as df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the global mean and global standard deviation: global_mean, global_std\n",
    "global_mean = df.mean()\n",
    "global_std = df.std()\n",
    "\n",
    "# Filter the US population from the origin column: us\n",
    "us = (df[df['origin']=='US'])\n",
    "\n",
    "# Compute the US mean and US standard deviation: us_mean, us_std\n",
    "us_mean = us.mean()\n",
    "us_std = us.std()\n",
    "\n",
    "# Print the differences\n",
    "print(us_mean - global_mean)\n",
    "print(us_std - global_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate and plot\n",
    "Population filtering can be used alongside plotting to quickly determine differences in distributions between the sub-populations. You'll work with the Titanic dataset.\n",
    "\n",
    "There were three passenger classes on the Titanic, and passengers in each class paid a different fare price. In this exercise, you'll investigate the differences in these fare prices.\n",
    "\n",
    "Your job is to use Boolean filtering and generate box plots of the fare prices for each of the three passenger classes. The fare prices are contained in the 'fare' column and passenger class information is contained in the 'pclass' column.\n",
    "\n",
    "When you're done, notice the portions of the box plots that differ and those that are similar.\n",
    "\n",
    "The DataFrame has been pre-loaded for you as titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the box plots on 3 separate rows and 1 column\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "\n",
    "# Generate a box plot of the fare prices for the First passenger class\n",
    "titanic.loc[titanic['pclass'] == 1].plot(ax=axes[0], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Second passenger class\n",
    "titanic.loc[titanic['pclass'] == 2].plot(ax=axes[1], y='fare', kind='box')\n",
    "\n",
    "# Generate a box plot of the fare prices for the Third passenger class\n",
    "titanic.loc[titanic['pclass'] == 3].plot(ax=axes[2], y='fare', kind='box')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and slicing times\n",
    "For this exercise, we have read in the same data file using three different approaches:\n",
    "\n",
    "df1 = pd.read_csv(filename)\n",
    "\n",
    "df2 = pd.read_csv(filename, parse_dates=['Date'])\n",
    "\n",
    "df3 = pd.read_csv(filename, index_col='Date', parse_dates=True)\n",
    "\n",
    "Use the .head() and .info() methods in the IPython Shell to inspect the DataFrames. Then, try to index each DataFrame with a datetime string. Which of the resulting DataFrames allows you to easily index and slice data by dates using, for example, `df1.loc['2010-Aug-01']`? \n",
    "\n",
    "--> ANS: df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and using a DatetimeIndex\n",
    "The pandas Index is a powerful way to handle time series data, so it is valuable to know how to build one yourself. Pandas provides the `pd.to_datetime()` function for just this task. For example, if passed the list of strings `['2015-01-01 091234','2015-01-01 091234']` and a format specification variable, such as `format='%Y-%m-%d %H%M%S`, pandas will parse the string into the proper datetime elements and build the datetime objects.\n",
    "\n",
    "In this exercise, a list of temperature data and a list of date strings has been pre-loaded for you as `temperature_list` and date_list respectively. Your job is to use the `.to_datetime()` method to build a DatetimeIndex out of the list of date strings, and to then use it along with the list of temperature data to build a pandas `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a format string: time_format\n",
    "time_format = '%Y-%m-%d %H:%M'\n",
    "\n",
    "# Convert date_list into a datetime object: my_datetimes\n",
    "my_datetimes = pd.to_datetime(date_list, format=time_format)  \n",
    "\n",
    "# Construct a pandas Series using temperature_list and my_datetimes: time_series\n",
    "time_series = pd.Series(temperature_list, index=my_datetimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial string indexing and slicing\n",
    "Pandas time series support \"partial string\" indexing. What this means is that even when passed only a portion of the datetime, such as the date but not the time, pandas is remarkably good at doing what one would expect. Pandas datetime indexing also supports a wide variety of commonly used datetime string formats, even when mixed.\n",
    "\n",
    "In this exercise, a time series that contains hourly weather data has been pre-loaded for you. This data was read using the parse_dates=True option in read_csv() with index_col=\"Dates\" so that the Index is indeed a DatetimeIndex.\n",
    "\n",
    "All data from the 'Temperature' column has been extracted into the variable ts0. Your job is to use a variety of natural date strings to extract one or more values from ts0.\n",
    "\n",
    "After you are done, you will have three new variables - ts1, ts2, and ts3. You can slice these further to extract only the first and last entries of each. Try doing this after your submission for more practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the hour from 9pm to 10pm on '2010-10-11': ts1\n",
    "ts1 = ts0.loc['2010-10-11 21:00:00':'2010-10-11 22:00:00']\n",
    "\n",
    "# Extract '2010-07-04' from ts0: ts2\n",
    "ts2 = ts0.loc['2010-07-04']\n",
    "\n",
    "# Extract data from '2010-12-15' to '2010-12-31': ts3\n",
    "ts3 = ts0.loc['2010-12-15':'2010-12-31']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
